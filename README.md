# Sistema Multiagente de ProducciÃ³n de Noticias

Sistema avanzado de generaciÃ³n de contenido periodÃ­stico usando **CrewAI** y **PlanificaciÃ³n HTN** (Hierarchical Task Network), con visualizaciÃ³n en tiempo real tipo n8n.

## ğŸ¯ CaracterÃ­sticas Principales

- **Arquitectura Multiagente Cooperativa**: 4 agentes especializados trabajando en conjunto
- **PlanificaciÃ³n HTN**: Basado en Russell & Norvig (AIMA Cap. 11.3)
- **Monitoreo de Sesgos**: VerificaciÃ³n activa de calidad y neutralidad
- **VisualizaciÃ³n en Tiempo Real**: Dashboard tipo n8n con Socket.IO
- **APIs Propias**: 100% independiente de servicios externos
- **âœ¨ NUEVO: Grounding Temporal** - Filtrado automÃ¡tico de fuentes obsoletas
- **âœ¨ NUEVO: TriangulaciÃ³n de Fuentes** - BÃºsqueda estructurada (oficial + internacional + local)
- **âœ¨ NUEVO: Sanity Check MatemÃ¡tico** - ValidaciÃ³n de coherencia lÃ³gica antes de publicar

## ğŸ“‚ Estructura del Proyecto

```
MultiAgent_AI_R/
â”œâ”€â”€ .env                # ConfiguraciÃ³n APIs
â”œâ”€â”€ app.py             # Servidor Flask + Socket.IO
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ llm_config.py  # LLM personalizado
â”‚   â”œâ”€â”€ tools.py       # ScraperRalf integration
â”‚   â”œâ”€â”€ callbacks.py   # Eventos tiempo real
â”‚   â””â”€â”€ crew.py        # Sistema HTN
â””â”€â”€ templates/
    â””â”€â”€ index.html     # Dashboard visual
```

---

# ğŸš€ GUÃA RÃPIDA DE USO

## Pre-requisitos

### 1. APIs Propias Funcionando

**API_RALF (LLM):**
- Debe estar accesible en la URL configurada en `.env`
- Compatible con API de OpenAI
- Endpoint: `/v1/chat/completions`

**ScraperRalf (BÃºsqueda):**
- Debe estar corriendo en `http://localhost:5000`
- Endpoint: `GET /api/search?q={query}&max_results={n}`
- Respuesta: `{"results": [{"title": "", "content": "", "source": ""}]}`

### 2. Python 3.9+

```bash
python --version  # Debe ser >= 3.9
```

## InstalaciÃ³n en 3 Pasos

### Paso 1: Instalar Dependencias

```bash
pip install -r requirements.txt
```

### Paso 2: Configurar .env

Editar el archivo `.env` y actualizar:

```bash
DOMINIO_API_RALF=tu-dominio-real.com
RALF_API_KEY=tu-api-key-si-aplica
```

### Paso 3: Verificar Setup

```bash
python setup_check.py
```

Si todo estÃ¡ âœ“, continuar. Si hay errores âœ—, corregir.

## EjecuciÃ³n

### Modo Completo (con Dashboard)

```bash
python app.py
```

Luego abrir en navegador: **http://localhost:8080**

### Modo CLI (solo backend, sin UI)

```bash
python src/crew.py
```

## Uso del Dashboard

1. **Ingresar tema** en el campo de texto
   - Ejemplo: "Inteligencia artificial en medicina"

2. **Clic en "Generar Noticia"**

3. **Observar el flujo en vivo:**
   - Nodos se iluminan cuando el agente estÃ¡ activo
   - Panel de logs muestra razonamiento en tiempo real
   - Conexiones muestran flujo de datos

4. **Leer el artÃ­culo generado**
   - Aparece al final del proceso
   - Formato profesional estilo periodÃ­stico

## Flujo del Proceso

```
1. Jefe de RedacciÃ³n recibe tema
   â†“
2. Asigna tarea a Investigador
   â†“
3. Investigador busca informaciÃ³n (ScraperRalf)
   â†“
4. Analista de Sesgos verifica calidad
   â†“
   â”œâ”€ SI detecta problemas â†’ Volver a paso 3
   â””â”€ SI aprueba â†’ Continuar
   â†“
5. Redactor escribe artÃ­culo
   â†“
6. Jefe revisa y publica
```

## Troubleshooting

### "No se puede conectar con API_RALF"

1. Verificar que el servicio estÃ© corriendo
2. Probar con curl:
   ```bash
   curl https://tu-dominio.com/v1/chat/completions
   ```
3. Revisar firewall/certificados SSL

### "ScraperRalf no disponible"

1. Iniciar el servicio ScraperRalf
2. Verificar que escucha en puerto 5000:
   ```bash
   curl http://localhost:5000/api/search?q=test
   ```

### "Socket.IO no conecta"

1. Revisar consola del navegador (F12)
2. Verificar que Flask estÃ© en `0.0.0.0:8080`
3. Deshabilitar temporalmente firewall/antivirus

### "MÃ³dulo no encontrado"

```bash
pip install -r requirements.txt --upgrade
```

## PersonalizaciÃ³n

### Cambiar temperatura de agentes

Editar [src/crew.py](src/crew.py):

```python
def get_investigator_llm():
    return config.get_llm(temperature=0.3)  # â† Cambiar aquÃ­
```

### Agregar nuevas herramientas

1. Crear clase en [src/tools.py](src/tools.py)
2. Heredar de `BaseTool`
3. Implementar mÃ©todo `_run()`
4. Asignar a agente en [src/crew.py](src/crew.py)

### Modificar personalidad de agentes

Editar `backstory` en [src/crew.py](src/crew.py), funciÃ³n `create_*_agent()`

## API REST Endpoints

### POST /api/generate

Inicia generaciÃ³n de noticia.

**Request:**
```json
{
  "topic": "Tu tema aquÃ­"
}
```

**Response:**
```json
{
  "status": "started",
  "session_id": "uuid-123",
  "topic": "Tu tema"
}
```

### GET /api/result/{session_id}

Obtiene resultado de sesiÃ³n.

**Response:**
```json
{
  "status": "success",
  "article": "ArtÃ­culo completo...",
  "session_id": "uuid-123"
}
```

### GET /api/health

Health check del sistema.

## Socket.IO Events

Namespace: `/agents`

**Eventos emitidos por el servidor:**

- `crew_start` - Inicio del proceso
- `agent_start` - Un agente comienza
- `agent_thinking` - Razonamiento del agente
- `tool_start` - Uso de herramienta
- `tool_end` - Fin de herramienta
- `agent_finish` - Agente completa tarea
- `crew_finish` - Proceso terminado
- `generation_complete` - ArtÃ­culo listo
- `error` - Error en el proceso

**Eventos enviados por el cliente:**

- `join_session` - Unirse a sesiÃ³n: `{session_id: "..."}`

---

# ğŸ“ ARQUITECTURA DEL SISTEMA

## Vista General

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SISTEMA MULTIAGENTE DE NOTICIAS              â”‚
â”‚                   (PlanificaciÃ³n HTN - Russell & Norvig)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                     â”‚                     â”‚
        â–¼                     â–¼                     â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Flask  â”‚          â”‚ CrewAI   â”‚         â”‚ Socket.IOâ”‚
   â”‚ Server â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ Agents   â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”‚ Events   â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                     â”‚                     â”‚
        â”‚                     â”‚                     â”‚
        â–¼                     â–¼                     â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚Dashboardâ”‚         â”‚   HTN    â”‚         â”‚ Frontend â”‚
   â”‚   UI    â”‚         â”‚ Planning â”‚         â”‚ Real-timeâ”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Capas del Sistema

### 1. Capa de PresentaciÃ³n (Frontend)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  templates/index.html                 â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚ â”‚  Dashboard Visual (estilo n8n)                  â”‚   â”‚
â”‚ â”‚  â€¢ Canvas de agentes (nodos animados)           â”‚   â”‚
â”‚ â”‚  â€¢ Panel de logs en tiempo real                 â”‚   â”‚
â”‚ â”‚  â€¢ VisualizaciÃ³n de conexiones                  â”‚   â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                       â”‚
â”‚  TecnologÃ­as:                                         â”‚
â”‚  - HTML5 + CSS3 (Grid, Flexbox, Animations)          â”‚
â”‚  - JavaScript (Socket.IO Client)                      â”‚
â”‚  - SVG para conexiones dinÃ¡micas                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. Capa de AplicaciÃ³n (Backend)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       app.py                          â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚ â”‚  Servidor Flask + Socket.IO                     â”‚   â”‚
â”‚ â”‚  â€¢ Endpoints REST (/api/generate, /api/result)  â”‚   â”‚
â”‚ â”‚  â€¢ Namespace Socket.IO (/agents)                â”‚   â”‚
â”‚ â”‚  â€¢ Threading para ejecuciÃ³n async               â”‚   â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                       â”‚
â”‚  Puertos:                                             â”‚
â”‚  - HTTP: 8080 (configurable)                          â”‚
â”‚  - WebSocket: Mismo puerto                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3. Capa de LÃ³gica de Negocio (Agentes)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    src/crew.py                        â”‚
â”‚                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚   Jefe de RedacciÃ³n (Manager)           â”‚          â”‚
â”‚  â”‚   â€¢ Coordina proceso HTN                â”‚          â”‚
â”‚  â”‚   â€¢ Temperature: 0.6                    â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                 â”‚ delega tareas                       â”‚
â”‚                 â–¼                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚   Investigador (Watchdog)               â”‚          â”‚
â”‚  â”‚   â€¢ Busca informaciÃ³n                   â”‚          â”‚
â”‚  â”‚   â€¢ Herramienta: NewsSearchTool         â”‚          â”‚
â”‚  â”‚   â€¢ Temperature: 0.3 (precisiÃ³n)        â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                 â”‚ pasa datos a                        â”‚
â”‚                 â–¼                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚   Analista de Sesgos (Critic)           â”‚          â”‚
â”‚  â”‚   â€¢ Verifica calidad                    â”‚          â”‚
â”‚  â”‚   â€¢ Detecta falacias/sesgos             â”‚          â”‚
â”‚  â”‚   â€¢ Temperature: 0.5 (balance)          â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                 â”‚ aprueba/rechaza                     â”‚
â”‚                 â–¼                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚   Redactor (Writer)                     â”‚          â”‚
â”‚  â”‚   â€¢ Escribe artÃ­culo final              â”‚          â”‚
â”‚  â”‚   â€¢ Estructura: PirÃ¡mide invertida      â”‚          â”‚
â”‚  â”‚   â€¢ Temperature: 0.8 (creatividad)      â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4. Capa de IntegraciÃ³n (Herramientas y LLM)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              src/tools.py + src/llm_config.py         â”‚
â”‚                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  NewsSearchTool     â”‚    â”‚  CustomLLM           â”‚ â”‚
â”‚  â”‚  â†“                  â”‚    â”‚  â†“                   â”‚ â”‚
â”‚  â”‚  ScraperRalf API    â”‚    â”‚  API_RALF            â”‚ â”‚
â”‚  â”‚  localhost:5000     â”‚    â”‚  (dominio en .env)   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                       â”‚
â”‚  Protocolo HTTP         Protocolo OpenAI-compatible  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5. Capa de Observabilidad (Callbacks)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  src/callbacks.py                     â”‚
â”‚                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚  RealtimeAgentCallback                  â”‚          â”‚
â”‚  â”‚                                         â”‚          â”‚
â”‚  â”‚  Intercepta:                            â”‚          â”‚
â”‚  â”‚  â€¢ on_agent_start  â†’ emit Socket.IO     â”‚          â”‚
â”‚  â”‚  â€¢ on_tool_start   â†’ emit Socket.IO     â”‚          â”‚
â”‚  â”‚  â€¢ on_agent_finish â†’ emit Socket.IO     â”‚          â”‚
â”‚  â”‚  â€¢ on_error        â†’ emit Socket.IO     â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                                       â”‚
â”‚  Eventos enviados al frontend en vivo                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Flujo de Datos (HTN)

```
1. Usuario ingresa tema en Frontend
   â”‚
   â–¼
2. POST /api/generate â†’ Flask Server
   â”‚
   â”œâ”€â”€ Genera session_id
   â”œâ”€â”€ Crea thread async
   â””â”€â”€ Retorna session_id al cliente
   â”‚
   â–¼
3. Cliente se une a namespace /agents con session_id
   â”‚
   â–¼
4. Thread ejecuta NewsCrew.run(topic)
   â”‚
   â”œâ”€â”€ Manager descompone tarea (HTN)
   â”‚   â”‚
   â”‚   â”œâ”€â”€ Task 1: InvestigaciÃ³n
   â”‚   â”‚   â”œâ”€â”€ Investigador activa NewsSearchTool
   â”‚   â”‚   â”œâ”€â”€ NewsSearchTool â†’ ScraperRalf API
   â”‚   â”‚   â””â”€â”€ Retorna datos crudos
   â”‚   â”‚
   â”‚   â”œâ”€â”€ Task 2: AnÃ¡lisis de Sesgos
   â”‚   â”‚   â”œâ”€â”€ Analista recibe output de Task 1
   â”‚   â”‚   â”œâ”€â”€ Ejecuta verificaciones
   â”‚   â”‚   â””â”€â”€ Aprueba o solicita re-bÃºsqueda
   â”‚   â”‚       â”‚
   â”‚   â”‚       â””â”€â”€ SI rechaza â†’ LOOP a Task 1
   â”‚   â”‚
   â”‚   â””â”€â”€ Task 3: RedacciÃ³n
   â”‚       â”œâ”€â”€ Redactor recibe output de Task 2
   â”‚       â”œâ”€â”€ Genera artÃ­culo (LLM con temp alta)
   â”‚       â””â”€â”€ Retorna texto final
   â”‚
   â–¼
5. Callbacks emiten eventos Socket.IO por cada paso
   â”‚
   â–¼
6. Frontend actualiza UI en tiempo real
   â”‚
   â”œâ”€â”€ Nodos se iluminan
   â”œâ”€â”€ Logs se agregan
   â””â”€â”€ Conexiones se animan
   â”‚
   â–¼
7. Al finalizar: emit 'generation_complete'
   â”‚
   â–¼
8. Frontend muestra artÃ­culo final
```

## ComunicaciÃ³n entre Componentes

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  HTTP POST    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  Kickoff   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Frontend â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  Flask   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ Crew   â”‚
â”‚         â”‚               â”‚  Server  â”‚            â”‚ Agents â”‚
â”‚         â”‚               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚         â”‚                    â”‚                       â”‚
â”‚         â”‚                    â”‚ Socket.IO Events      â”‚
â”‚         â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚         â”‚                    â”‚                       
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”           
                          â”‚Callbacks â”‚           
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           
                          
Leyenda:
â”€â”€â–º Flujo de control
..â–º Flujo de datos
â—„â”€â–º ComunicaciÃ³n bidireccional
```

## TeorÃ­a Aplicada (AIMA)

### PlanificaciÃ³n HTN (Cap. 11.3)

```
TAREA COMPUESTA: ProducirNoticia(tema)
â”œâ”€â”€ MÃ‰TODO: Proceso_EstÃ¡ndar
â”‚   â”œâ”€â”€ PRIMITIVA: Buscar(tema)           [Investigador]
â”‚   â”œâ”€â”€ PRIMITIVA: Validar(info)          [Analista]
â”‚   â””â”€â”€ PRIMITIVA: Redactar(info_vÃ¡lida)  [Redactor]
â”‚
â””â”€â”€ MÃ‰TODO: Proceso_Con_CorrecciÃ³n (si Validar falla)
    â”œâ”€â”€ PRIMITIVA: Buscar(tema)
    â”œâ”€â”€ PRIMITIVA: Validar(info)
    â”œâ”€â”€ SI rechazado:
    â”‚   â””â”€â”€ RECURSIÃ“N: Buscar(tema_refinado)
    â””â”€â”€ PRIMITIVA: Redactar(info_vÃ¡lida)
```

### Vigilancia de EjecuciÃ³n (Cap. 12.5)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Analista (Monitor de EjecuciÃ³n)   â”‚
â”‚                                     â”‚
â”‚  PRECONDICIONES verificadas:        â”‚
â”‚  1. â‰¥ 2 fuentes independientes      â”‚
â”‚  2. Ausencia de falacias lÃ³gicas    â”‚
â”‚  3. Lenguaje neutral                â”‚
â”‚  4. Datos verificables              â”‚
â”‚                                     â”‚
â”‚  SI precondiciÃ³n falla:             â”‚
â”‚  â†’ Trigger replanificaciÃ³n          â”‚
â”‚  â†’ Backtracking a bÃºsqueda          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## TecnologÃ­as Clave

| Componente | TecnologÃ­a | PropÃ³sito |
|------------|-----------|-----------|
| Backend | Flask 3.0 | Servidor web |
| Real-time | Socket.IO | ComunicaciÃ³n bidireccional |
| Agentes | CrewAI 0.28 | Framework multiagente |
| LLM | LangChain + Custom | IntegraciÃ³n con API_RALF |
| Herramientas | BaseTool | ExtensiÃ³n de capacidades |
| Frontend | HTML5/CSS3/JS | Interfaz visual |
| Callback | Custom Handler | Observabilidad |

## Seguridad y ConfiguraciÃ³n

```
.env (NO commitear - contiene secrets)
â”œâ”€â”€ DOMINIO_API_RALF=<URL del LLM>
â”œâ”€â”€ RALF_API_KEY=<API Key si aplica>
â”œâ”€â”€ SCRAPER_BASE_URL=http://localhost:5000
â””â”€â”€ FLASK_SECRET_KEY=<Secreto para sesiones>

.gitignore
â”œâ”€â”€ .env
â”œâ”€â”€ __pycache__/
â””â”€â”€ *.log
```

---

# ğŸ“¡ ARQUITECTURA DE INTEGRACIÃ“N DE APIS

## ğŸ”„ Flujo Completo del Sistema

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          FRONTEND (index.html)                              â”‚
â”‚  Usuario ingresa tema â†’ POST /api/generate â†’ Socket.IO listening           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        BACKEND (app.py - Flask)                             â”‚
â”‚  Thread asÃ­ncrono ejecuta â†’ generate_news_article(topic, session_id)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   ORQUESTADOR (src/crew.py - NewsCrew)                      â”‚
â”‚  Bucle HTN con backtracking:                                                â”‚
â”‚    IteraciÃ³n 1,2,3:                                                         â”‚
â”‚      â”œâ”€ FASE 1: Investigador                                                â”‚
â”‚      â”œâ”€ FASE 2: Analista (verifica calidad)                                 â”‚
â”‚      â””â”€ FASE 3: Redactor (solo si APROBADO)                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚                             â”‚
            â–¼                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  HERRAMIENTA          â”‚      â”‚  CEREBRO (LLM)         â”‚
â”‚  ScraperRalf          â”‚      â”‚  API_RALF              â”‚
â”‚  (tools.py)           â”‚      â”‚  (llm_config.py)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚                             â”‚
            â”‚                             â”‚
            â–¼                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  API SCRAPER          â”‚      â”‚  PROXY LOCAL           â”‚
â”‚  127.0.0.1:5000       â”‚      â”‚  127.0.0.1:11434       â”‚
â”‚  /api/search          â”‚      â”‚  /v1/chat/completions  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚                             â”‚
            â”‚                             â”‚
            â–¼                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  NOTICIAS REALES      â”‚      â”‚  API_RALF REAL         â”‚
â”‚  (Peru: RPP, El       â”‚      â”‚  ygggo88wk0...sslip.io â”‚
â”‚   Comercio, etc.)     â”‚      â”‚  /chat                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ› ï¸ DETALLE POR COMPONENTE

### 1ï¸âƒ£ **API_RALF (LLM Brain)**

#### Flujo de EjecuciÃ³n:

```python
# PASO 1: Agente necesita razonar
agent.execute_task("Buscar noticias sobre IA")

# PASO 2: llm_config.py crea ChatOpenAI
llm = ChatOpenAI(
    base_url="http://127.0.0.1:11434/v1",  # â† PROXY LOCAL
    model="ralf-mixed-model",
    temperature=0.3
)

# PASO 3: Agent envÃ­a prompt al LLM
response = llm.invoke("Â¿QuÃ© buscar sobre IA?")
```

#### TraducciÃ³n en Proxy (ralf_proxy.py):

```python
# ENTRADA (Formato OpenAI):
{
  "model": "ralf-mixed-model",
  "messages": [
    {"role": "system", "content": "Eres un investigador experto..."},
    {"role": "user", "content": "Busca noticias sobre IA"}
  ],
  "temperature": 0.3
}

# â†“ CONVERSIÃ“N â†“

# SALIDA (Formato API_RALF):
{
  "messages": [
    {"role": "system", "content": "Eres un investigador experto..."},
    {"role": "user", "content": "Busca noticias sobre IA"}
  ]
}

# â†“ HTTP POST â†“
# http://ygggo88wk0wo8ogckoscgw0o.72.62.170.143.sslip.io/chat

# â†“ RESPUESTA API_RALF (Streaming) â†“
"Voy a buscar noticias sobre avances en IA en medicina y robÃ³tica..."

# â†“ CONVERSIÃ“N DE VUELTA â†“

# RESPUESTA (Formato OpenAI):
{
  "id": "chatcmpl-proxy",
  "object": "chat.completion",
  "model": "ralf-mixed-model",
  "choices": [{
    "index": 0,
    "message": {
      "role": "assistant",
      "content": "Voy a buscar noticias sobre avances en IA..."
    },
    "finish_reason": "stop"
  }]
}
```

**ğŸ”‘ Clave:** El proxy actÃºa como "traductor simultÃ¡neo" entre el formato que espera LangChain (OpenAI) y el que usa tu API_RALF.

---

### 2ï¸âƒ£ **ScraperRalf (News Search)**

#### Flujo de EjecuciÃ³n:

```python
# PASO 1: Investigator Agent usa herramienta
tool = NewsSearchTool()
result = tool._run(
    query="inteligencia artificial medicina",
    max_results=5
)

# PASO 2: tools.py hace HTTP GET
endpoint = "http://127.0.0.1:5000/api/search"
params = {
    "q": "inteligencia artificial medicina",
    "max_results": 5
}

response = requests.get(endpoint, params=params, timeout=30)
```

#### Formato de Respuesta de ScraperRalf:

```json
{
  "status": "success",
  "query": "inteligencia artificial medicina",
  "total_results": 5,
  "results": [
    {
      "id": 1,
      "title": "IA revoluciona diagnÃ³sticos mÃ©dicos en PerÃº",
      "content": "Hospitales peruanos implementan algoritmos...",
      "source": "RPP Noticias",
      "url": "https://rpp.pe/tecnologia/..."
    },
    {
      "id": 2,
      "title": "Robots quirÃºrgicos con IA llegan a Lima",
      "content": "El Hospital Rebagliati incorporÃ³...",
      "source": "El Comercio",
      "url": "https://elcomercio.pe/salud/..."
    }
    // ... 3 mÃ¡s
  ]
}
```

**ğŸ”‘ Clave:** ScraperRalf agrega noticias de mÃºltiples fuentes peruanas (RPP, El Comercio, GestiÃ³n, etc.) y devuelve JSON limpio y estructurado.

---

## ğŸ“¤ FORMATO DE RESPUESTA FINAL

### Flujo de GeneraciÃ³n del ArtÃ­culo:

```python
# 1. Investigator recopila informaciÃ³n (JSON de ScraperRalf)
investigation_result = """
FUENTES CONSULTADAS:
- RPP: IA en medicina (credibilidad: alta)
- El Comercio: Robots quirÃºrgicos (credibilidad: alta)
...
"""

# 2. Analyst valida y aprueba
analysis_result = """
VEREDICTO: APROBADO
HECHOS VALIDADOS:
- Hospital Rebagliati implementÃ³ robot quirÃºrgico
- Sistema de IA diagnostica con 95% de precisiÃ³n
...
"""

# 3. Writer genera artÃ­culo en MARKDOWN
final_article = """
# IA Revoluciona la Medicina en PerÃº

**Lima, 4 de enero de 2026** - Los hospitales peruanos estÃ¡n...

## RobÃ³tica QuirÃºrgica Avanza

El Hospital Rebagliati incorporÃ³ un sistema de cirugÃ­a asistida...

## DiagnÃ³sticos MÃ¡s Precisos

Estudios demuestran que los algoritmos de IA logran una precisiÃ³n...

### Fuentes
- RPP Noticias: https://rpp.pe/...
- El Comercio: https://elcomercio.pe/...
"""
```

### Entrega al Frontend:

```javascript
// Backend devuelve JSON:
{
  "status": "success",
  "topic": "IA en medicina PerÃº",
  "article": "# IA Revoluciona...\n\n**Lima**...",  // â† MARKDOWN CRUDO
  "iterations": 1,
  "session_id": "abc123"
}

// Frontend recibe y DEBE convertir Markdown â†’ HTML
```

---

# ğŸ“Š FLUJO DE DATOS DETALLADO - SISTEMA MULTIAGENTE

## ğŸ¯ Caso de Uso Completo: "Avances en IA en Medicina Peruana"

---

### ğŸ“¥ FASE 1: INICIO DE SESIÃ“N

```
USUARIO (Frontend)
â”‚
â”œâ”€ Ingresa: "Avances en IA en medicina peruana"
â”œâ”€ Click: "Deploy Agents"
â”‚
â–¼
POST http://localhost:8080/api/generate
Body: {"topic": "Avances en IA en medicina peruana"}
â”‚
â–¼
RESPUESTA:
{
  "status": "started",
  "session_id": "abc-123-xyz",
  "topic": "Avances en IA en medicina peruana"
}
â”‚
â–¼
Socket.IO: join_session({"session_id": "abc-123-xyz"})
```

---

### ğŸ”„ FASE 2: ITERACIÃ“N 1 - INVESTIGACIÃ“N

```
BACKEND (app.py â†’ crew.py)
â”‚
â”œâ”€ NewsCrew.run(topic="Avances en IA en medicina peruana")
â”‚
â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AGENTE: INVESTIGADOR                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â”œâ”€ Socket.IO emit: agent_start
â”‚  {
â”‚    "agent": "Investigador de Noticias",
â”‚    "message": "ğŸ¤– Investigador activando sensores..."
â”‚  }
â”‚
â”œâ”€ LLM (API_RALF) decide estrategia de bÃºsqueda
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  â”‚ PASO 1: ChatOpenAI.invoke()                 â”‚
â”‚  â”‚ Prompt: "Eres investigador experto. Busca   â”‚
â”‚  â”‚         informaciÃ³n sobre: {topic}"         â”‚
â”‚  â”‚                                              â”‚
â”‚  â”‚ â†“ llm_config.py                             â”‚
â”‚  â”‚                                              â”‚
â”‚  â”‚ POST http://127.0.0.1:11434/v1/chat/...     â”‚
â”‚  â”‚ Body (OpenAI format):                       â”‚
â”‚  â”‚ {                                            â”‚
â”‚  â”‚   "model": "ralf-mixed-model",              â”‚
â”‚  â”‚   "messages": [{                             â”‚
â”‚  â”‚     "role": "system",                        â”‚
â”‚  â”‚     "content": "Eres investigador..."       â”‚
â”‚  â”‚   }],                                        â”‚
â”‚  â”‚   "temperature": 0.3                         â”‚
â”‚  â”‚ }                                            â”‚
â”‚  â”‚                                              â”‚
â”‚  â”‚ â†“ ralf_proxy.py CONVIERTE                   â”‚
â”‚  â”‚                                              â”‚
â”‚  â”‚ POST http://ygggo88...sslip.io/chat         â”‚
â”‚  â”‚ Body (RALF format):                         â”‚
â”‚  â”‚ {                                            â”‚
â”‚  â”‚   "messages": [{                             â”‚
â”‚  â”‚     "role": "system",                        â”‚
â”‚  â”‚     "content": "Eres investigador..."       â”‚
â”‚  â”‚   }]                                         â”‚
â”‚  â”‚ }                                            â”‚
â”‚  â”‚                                              â”‚
â”‚  â”‚ â†“ API_RALF RESPONDE (streaming)             â”‚
â”‚  â”‚                                              â”‚
â”‚  â”‚ "Voy a buscar usando tÃ©rminos especÃ­ficos:  â”‚
â”‚  â”‚  'inteligencia artificial hospital perÃº',   â”‚
â”‚  â”‚  'IA diagnÃ³stico mÃ©dico Lima', etc."        â”‚
â”‚  â”‚                                              â”‚
â”‚  â”‚ â†“ PROXY CONVIERTE DE VUELTA                 â”‚
â”‚  â”‚                                              â”‚
â”‚  â”‚ Response (OpenAI format):                   â”‚
â”‚  â”‚ {                                            â”‚
â”‚  â”‚   "choices": [{                              â”‚
â”‚  â”‚     "message": {                             â”‚
â”‚  â”‚       "content": "Voy a buscar usando..."   â”‚
â”‚  â”‚     }                                        â”‚
â”‚  â”‚   }]                                         â”‚
â”‚  â”‚ }                                            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â”œâ”€ LLM decide: "Usar herramienta news_search"
â”‚
â”œâ”€ Socket.IO emit: tool_start
â”‚  {
â”‚    "agent": "Investigador de Noticias",
â”‚    "tool": "news_search",
â”‚    "message": "ğŸ”§ Usando herramienta: news_search"
â”‚  }
â”‚
â”œâ”€ NewsSearchTool._run()
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  â”‚ PASO 2: ScraperRalf Query                   â”‚
â”‚  â”‚                                              â”‚
â”‚  â”‚ GET http://127.0.0.1:5000/api/search        â”‚
â”‚  â”‚ Params:                                      â”‚
â”‚  â”‚   ?q=inteligencia artificial hospital perÃº  â”‚
â”‚  â”‚   &max_results=5                             â”‚
â”‚  â”‚                                              â”‚
â”‚  â”‚ â†“ ScraperRalf BUSCA EN FUENTES REALES       â”‚
â”‚  â”‚                                              â”‚
â”‚  â”‚ [RPP.pe] Scraped: "IA en Hospital..."       â”‚
â”‚  â”‚ [ElComercio.pe] Scraped: "Robots mÃ©dicos.." â”‚
â”‚  â”‚ [Gestion.pe] Scraped: "Telemedicina IA..."  â”‚
â”‚  â”‚                                              â”‚
â”‚  â”‚ â†“ RESPUESTA JSON                             â”‚
â”‚  â”‚                                              â”‚
â”‚  â”‚ {                                            â”‚
â”‚  â”‚   "status": "success",                       â”‚
â”‚  â”‚   "total_results": 5,                        â”‚
â”‚  â”‚   "results": [                               â”‚
â”‚  â”‚     {                                        â”‚
â”‚  â”‚       "id": 1,                               â”‚
â”‚  â”‚       "title": "IA revoluciona diagnÃ³stico..",â”‚
â”‚  â”‚       "content": "Hospital Rebagliati...",  â”‚
â”‚  â”‚       "source": "RPP Noticias",             â”‚
â”‚  â”‚       "url": "https://rpp.pe/..."           â”‚
â”‚  â”‚     },                                       â”‚
â”‚  â”‚     {                                        â”‚
â”‚  â”‚       "id": 2,                               â”‚
â”‚  â”‚       "title": "Robots quirÃºrgicos IA...",  â”‚
â”‚  â”‚       "content": "ClÃ­nica San Felipe...",   â”‚
â”‚  â”‚       "source": "El Comercio",              â”‚
â”‚  â”‚       "url": "https://elcomercio.pe/..."    â”‚
â”‚  â”‚     }                                        â”‚
â”‚  â”‚     // ... 3 mÃ¡s                             â”‚
â”‚  â”‚   ]                                          â”‚
â”‚  â”‚ }                                            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â”œâ”€ Socket.IO emit: tool_end
â”‚  {
â”‚    "tool": "news_search",
â”‚    "message": "âœ… Encontrados 5 artÃ­culos"
â”‚  }
â”‚
â”œâ”€ LLM procesa resultados y genera informe
â”‚  (API_RALF nuevamente, mismo flujo de proxy)
â”‚
â”‚  INFORME GENERADO:
â”‚  """
â”‚  FUENTES CONSULTADAS:
â”‚  
â”‚  1. RPP Noticias (Credibilidad: Alta)
â”‚     - TÃ­tulo: "IA revoluciona diagnÃ³sticos en PerÃº"
â”‚     - Hechos: Hospital Rebagliati implementÃ³ sistema...
â”‚     - URL: https://rpp.pe/tecnologia/...
â”‚  
â”‚  2. El Comercio (Credibilidad: Alta)
â”‚     - TÃ­tulo: "Robots quirÃºrgicos con IA en Lima"
â”‚     - Hechos: ClÃ­nica San Felipe adquiriÃ³ robot...
â”‚     - URL: https://elcomercio.pe/salud/...
â”‚  
â”‚  DATOS CLAVE:
â”‚  - 3 hospitales peruanos usan IA para diagnÃ³stico
â”‚  - PrecisiÃ³n del 95% en detecciÃ³n de cÃ¡ncer
â”‚  - ReducciÃ³n de 40% en tiempo de diagnÃ³stico
â”‚  """
â”‚
â–¼
Socket.IO emit: agent_finish
{
  "agent": "Investigador de Noticias",
  "message": "âœ… InvestigaciÃ³n completada"
}
```

---

### ğŸ” FASE 3: ANÃLISIS DE SESGOS

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AGENTE: ANALISTA                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â”œâ”€ Socket.IO emit: agent_start
â”‚  {"agent": "Analista de Sesgos y Fact-Checker"}
â”‚
â”œâ”€ Recibe informe del Investigador
â”‚
â”œâ”€ LLM (API_RALF) analiza con prompt especializado:
â”‚  "Eres analista crÃ­tico. Verifica falacias, sesgos,
â”‚   credibilidad de fuentes. VEREDICTO: APROBADO/RECHAZADO"
â”‚  
â”‚  (Mismo flujo: ChatOpenAI â†’ Proxy â†’ API_RALF)
â”‚
â”‚  ANÃLISIS GENERADO:
â”‚  """
â”‚  VEREDICTO: APROBADO
â”‚  
â”‚  VERIFICACIONES:
â”‚  âœ… Falacias lÃ³gicas: No detectadas
â”‚  âœ… Sesgos: Lenguaje neutral detectado
â”‚  âœ… Fuentes: RPP y El Comercio son confiables
â”‚  âœ… Balance: Presenta datos objetivos sin agenda
â”‚  
â”‚  HECHOS VALIDADOS:
â”‚  - Hospital Rebagliati usa IA (verificado)
â”‚  - 95% precisiÃ³n (citado en fuente original)
â”‚  - 3 hospitales peruanos (confirmado)
â”‚  
â”‚  LUZ VERDE PARA REDACCIÃ“N âœ…
â”‚  """
â”‚
â–¼
Socket.IO emit: agent_finish
{"agent": "Analista...", "message": "âœ… Calidad aprobada"}
```

**ğŸ”„ SI FUERA RECHAZADO:**
```
VEREDICTO: RECHAZADO

PROBLEMAS:
- Falta perspectiva de mÃ©dicos peruanos
- Solo fuentes de Lima, Â¿quÃ© pasa en regiones?

Socket.IO emit: backtracking
{
  "message": "ğŸ”„ RECHAZADO: Volviendo a investigar...",
  "feedback": "Buscar testimonios mÃ©dicos y datos regionales"
}

â†’ VUELVE A FASE 2 (IteraciÃ³n 2)
```

---

### âœï¸ FASE 4: REDACCIÃ“N

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AGENTE: REDACTOR                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â”œâ”€ Socket.IO emit: agent_start
â”‚  {"agent": "Redactor Senior"}
â”‚
â”œâ”€ Recibe hechos validados del Analista
â”‚
â”œâ”€ LLM (API_RALF) genera artÃ­culo con prompt:
â”‚  "Eres redactor profesional. Estructura: pirÃ¡mide invertida.
â”‚   Usa SOLO hechos validados. Formato: MARKDOWN"
â”‚  
â”‚  (Mismo flujo: ChatOpenAI â†’ Proxy â†’ API_RALF)
â”‚
â”‚  ARTÃCULO GENERADO (MARKDOWN):
â”‚  """
â”‚  # IA Revoluciona la Medicina en Hospitales Peruanos
â”‚  
â”‚  **Lima, 4 de enero de 2026** - La inteligencia artificial 
â”‚  estÃ¡ transformando el diagnÃ³stico mÃ©dico en PerÃº, con tres 
â”‚  hospitales lÃ­deres implementando sistemas que alcanzan una 
â”‚  precisiÃ³n del 95% en la detecciÃ³n temprana de cÃ¡ncer.
â”‚  
â”‚  ## TecnologÃ­a en AcciÃ³n
â”‚  
â”‚  El Hospital Rebagliati, uno de los mÃ¡s grandes del paÃ­s, 
â”‚  incorporÃ³ un sistema de IA que analiza imÃ¡genes mÃ©dicas 
â”‚  con una velocidad 40% superior a los mÃ©todos tradicionales.
â”‚  
â”‚  > "Esta tecnologÃ­a nos permite salvar mÃ¡s vidas", seÃ±ala 
â”‚  > el Dr. Carlos Mendoza, jefe de OncologÃ­a.
â”‚  
â”‚  ### Datos Clave:
â”‚  
â”‚  - **95%** de precisiÃ³n en diagnÃ³sticos
â”‚  - **3 hospitales** usando IA activamente
â”‚  - **40%** reducciÃ³n en tiempo de diagnÃ³stico
â”‚  
â”‚  ## Impacto Regional
â”‚  
â”‚  MÃ¡s allÃ¡ de Lima, la ClÃ­nica San Felipe estÃ¡ probando...
â”‚  
â”‚  ### Fuentes
â”‚  
â”‚  - [RPP Noticias](https://rpp.pe/tecnologia/...)
â”‚  - [El Comercio](https://elcomercio.pe/salud/...)
â”‚  """
â”‚
â–¼
Socket.IO emit: agent_finish
{"agent": "Redactor Senior", "output": "ArtÃ­culo completo"}
```

---

### ğŸ“¤ FASE 5: ENTREGA AL FRONTEND

```
BACKEND (app.py)
â”‚
â”œâ”€ Crew completada exitosamente
â”‚
â”œâ”€ Socket.IO emit: generation_complete
â”‚  {
â”‚    "status": "success",
â”‚    "topic": "Avances en IA en medicina peruana",
â”‚    "article": "# IA Revoluciona...\n\n**Lima**...",  â† MARKDOWN
â”‚    "iterations": 1,
â”‚    "session_id": "abc-123-xyz"
â”‚  }
â”‚
â–¼
FRONTEND (index.html)
â”‚
â”œâ”€ Evento recibido: generation_complete
â”‚
â”œâ”€ Ejecuta: displayResult(data.article)
â”‚
â”œâ”€ RENDERIZADO MARKDOWN â†’ HTML:
â”‚  
â”‚  Input (Markdown):
â”‚  # IA Revoluciona...
â”‚  **Lima, 4 de enero**...
â”‚  
â”‚  Processing:
â”‚  1. Escapar HTML peligroso
â”‚  2. Convertir headers (# â†’ <h1>)
â”‚  3. Convertir bold (**texto** â†’ <strong>)
â”‚  4. Convertir links ([texto](url) â†’ <a>)
â”‚  5. Convertir listas (- item â†’ <li>)
â”‚  6. Convertir cÃ³digo (`code` â†’ <code>)
â”‚  7. Agrupar pÃ¡rrafos (<p>)
â”‚  
â”‚  Output (HTML estilizado):
â”‚  <h1 class="text-5xl font-bold text-[#9D1A10]">
â”‚    IA Revoluciona la Medicina en Hospitales Peruanos
â”‚  </h1>
â”‚  
â”‚  <p class="mb-4 leading-relaxed text-neutral-700">
â”‚    <strong class="font-bold">Lima, 4 de enero de 2026</strong> - 
â”‚    La inteligencia artificial estÃ¡ transformando...
â”‚  </p>
â”‚  
â”‚  <h2 class="text-4xl font-bold border-b-2 border-[#9D1A10]">
â”‚    TecnologÃ­a en AcciÃ³n
â”‚  </h2>
â”‚  
â”‚  <blockquote class="border-l-4 border-[#9D1A10] italic">
â”‚    "Esta tecnologÃ­a nos permite salvar mÃ¡s vidas"
â”‚  </blockquote>
â”‚  
â”‚  <ul class="my-4">
â”‚    <li class="ml-6 list-disc"><strong>95%</strong> de precisiÃ³n...</li>
â”‚    <li class="ml-6 list-disc"><strong>3 hospitales</strong>...</li>
â”‚  </ul>
â”‚
â”œâ”€ Inyecta HTML en <div id="resultArticle">
â”‚
â”œâ”€ Scroll suave a secciÃ³n "Intelligence Report"
â”‚
â–¼
USUARIO VE ARTÃCULO FORMATEADO BELLAMENTE
```

---

## ğŸ“Š RESUMEN FLUJO DE DATOS

```
FORMATO POR ETAPA:

1. Frontend Input:     Plain Text
   "Avances en IA medicina peruana"

2. ScraperRalf:        JSON estructurado
   {"results": [...]}

3. LLM Responses:      Plain Text / Reasoning
   "Voy a buscar usando tÃ©rminos..."

4. Investigator Out:   Markdown/Plain Text
   "FUENTES:\n- RPP..."

5. Analyst Out:        Markdown/Plain Text
   "VEREDICTO: APROBADO\n..."

6. Writer Out:         **MARKDOWN**
   "# TÃ­tulo\n\n**Lead**..."

7. Frontend Display:   **HTML Estilizado**
   <h1 class="...">TÃ­tulo</h1>...
```

---

# ğŸ” INTEGRACIÃ“N CON SCRAPERRALF - ANÃLISIS COMPLETO

## ğŸ“Š Estado Actual del Sistema

### ConfiguraciÃ³n Actual (src/tools.py)

```python
# LLAMADA ACTUAL - SIMPLE
response = requests.get(
    "http://127.0.0.1:5000/api/search",
    params={
        "q": "inteligencia artificial medicina",
        "max_results": 5  # â† Por fuente, NO total
    },
    timeout=30  # â† PROBLEMA: Las fuentes locales tardan ~60s
)
```

### âš ï¸ PROBLEMA CRÃTICO

**Timeout de 30 segundos VS Tiempo real de ScraperRalf:**

| Fuente | Tipo | Tiempo | Calidad Contenido |
|--------|------|--------|-------------------|
| **La RepÃºblica** | Local | ~45-60s | â­â­â­â­â­ (100% del artÃ­culo) |
| **El Comercio** | Local | ~30-45s | â­â­â­â­â­ (JSON-LD completo) |
| **Infobae** | Local | ~60-90s | â­â­â­â­â­ (Browser automation) |
| **NewsAPI** | API Global | ~2-3s | â­â­â­ (Snippets truncados) |
| **TheNewsAPI** | API Global | ~2-3s | â­â­â­ (ResÃºmenes) |

**Resultado actual:** Con `timeout=30`, estÃ¡s perdiendo:
- âŒ La RepÃºblica (truncado a 30s)
- âŒ Infobae (siempre timeout)
- âœ… El Comercio (a veces pasa)
- âœ… APIs globales (siempre funcionan)

---

## ğŸ¯ ESTRATEGIA DE OPTIMIZACIÃ“N

### OpciÃ³n 1: Dos Fases de BÃºsqueda (Recomendado)

```python
# FASE 1: BÃšSQUEDA RÃPIDA (APIs Globales) - 5 segundos
# â†’ Para obtener contexto general y titulares

# FASE 2: BÃšSQUEDA PROFUNDA (Scrapers Locales) - 90 segundos
# â†’ Para extraer contenido completo y citas textuales
```

### OpciÃ³n 2: BÃºsqueda Paralela Inteligente

ScraperRalf ya usa `ThreadPoolExecutor` internamente, asÃ­ que todas las fuentes se consultan en paralelo. El tiempo total es el de la fuente **mÃ¡s lenta**.

**ConfiguraciÃ³n Ã³ptima:**
```python
timeout = 90  # Esperar a que Infobae (la mÃ¡s lenta) termine
```

---

## ğŸ’¡ IMPLEMENTACIÃ“N RECOMENDADA

### Estrategia 1: "Fast-First, Deep-Later"

Voy a modificar `NewsSearchTool` para hacer dos llamadas:

```python
def _run(self, query: str, max_results: Optional[int] = None) -> str:
    """
    Estrategia de dos fases:
    1. BÃºsqueda rÃ¡pida (APIs) para contexto inmediato
    2. BÃºsqueda profunda (Scrapers) para anÃ¡lisis detallado
    """
    
    # FASE 1: APIs Globales (RÃ¡pidas) - 5s timeout
    # ScraperRalf deberÃ­a tener endpoint: /api/search/fast
    # que solo consulte NewsAPI + TheNewsAPI
    
    fast_results = self._search_fast(query, max_results)
    
    # FASE 2: Scrapers Locales (Lentas) - 90s timeout
    # Endpoint: /api/search/deep (solo El Comercio, La RepÃºblica, Infobae)
    
    deep_results = self._search_deep(query, max_results)
    
    # COMBINAR: Priorizar contenido completo de locales
    return self._merge_results(fast_results, deep_results)
```

### Estrategia 2: "Deep-Only con Timeout Largo"

MÃ¡s simple pero mÃ¡s lenta:

```python
# Solo llamar a /api/search con timeout largo
response = requests.get(
    endpoint,
    params=params,
    timeout=90  # â† AUMENTADO para permitir Infobae
)
```

---

## ğŸ“¡ DATOS QUE OBTIENES DE SCRAPERRALF

### Respuesta TÃ­pica (5 fuentes en paralelo):

```json
{
  "success": true,
  "total": 15,  // 3 de cada fuente
  "search_time_seconds": 62.5,  // Limitado por Infobae
  "results": [
    // ========================================
    // TIER 1: FUENTES LOCALES (Contenido 100%)
    // ========================================
    {
      "title": "BCR reduce tasa de interÃ©s de referencia a 5.75%",
      "content": "El Banco Central de Reserva del PerÃº (BCRP) decidiÃ³ reducir en 25 puntos bÃ¡sicos su tasa de interÃ©s de referencia, de 6.00% a 5.75%, segÃºn informÃ³ en su comunicado oficial del jueves 14 de marzo. Esta es la primera reducciÃ³n en 18 meses, luego de un ciclo de alzas para controlar la inflaciÃ³n que alcanzÃ³ un pico de 8.81% en junio de 2022. SegÃºn el presidente del BCR, Julio Velarde, 'la decisiÃ³n refleja la mejora en las expectativas inflacionarias y la recuperaciÃ³n gradual de la actividad econÃ³mica'. El comunicado del BCRP seÃ±ala que la inflaciÃ³n interanual de febrero se ubicÃ³ en 3.2%, dentro del rango meta de 1% a 3%, con una proyecciÃ³n de cerrar 2024 en 2.5%. Analistas del Banco de CrÃ©dito del PerÃº (BCP) comentaron que...",
      "source": "La RepÃºblica",
      "date": "2024-03-15T10:30:00",
      "url": "https://larepublica.pe/economia/2024/03/15/bcr-reduce-tasa-de-interes-inflacion-peru",
      "image_url": "https://larepublica.pe/resizer/...",
      "method": "CSS Selector"  // MÃ©todo de extracciÃ³n
    },
    {
      "title": "Tasa del BCR baja por primera vez desde 2022",
      "content": "Lima, 14 de marzo. La autoridad monetaria del paÃ­s optÃ³ por reducir la tasa de polÃ­tica monetaria (TPM) en un cuarto de punto porcentual, llevÃ¡ndola de 6% a 5.75%, en lÃ­nea con las proyecciones del mercado. Esta medida busca impulsar el crÃ©dito y la inversiÃ³n privada en un contexto de desaceleraciÃ³n econÃ³mica global. SegÃºn el anÃ¡lisis de la Sociedad Nacional de Industrias (SNI), esta reducciÃ³n podrÃ­a traducirse en menores tasas de interÃ©s para prÃ©stamos empresariales y crÃ©ditos hipotecarios en los prÃ³ximos meses. El documento del BCRP destaca que...",
      "source": "El Comercio",
      "date": "2024-03-14T18:45:00",
      "url": "https://elcomercio.pe/economia/peru/bcr-tasa-interes-referencia-reduccion-inflacion-noticia/",
      "image_url": "https://img.elcomercio.pe/...",
      "method": "JSON-LD"
    },
    {
      "title": "Banco Central recorta tasa de referencia ante mejora inflacionaria",
      "content": "La directiva del Banco Central de Reserva (BCR) aprobÃ³ este jueves reducir la tasa de interÃ©s de polÃ­tica monetaria de 6.00% a 5.75%, marcando un cambio en la postura restrictiva que mantuvo desde mediados de 2022. En su comunicado, el BCR argumenta que 'la convergencia de la inflaciÃ³n hacia el rango meta, junto con la mejora de las expectativas de los agentes econÃ³micos, permite una postura menos restrictiva'. Expertos consultados seÃ±alan que...",
      "source": "Infobae",
      "date": "2024-03-14T20:15:00",
      "url": "https://www.infobae.com/peru/2024/03/14/bcr-reduce-tasa-interes/",
      "image_url": "https://www.infobae.com/new-resizer/...",
      "method": "Browser Automation"
    },

    // ========================================
    // TIER 2: APIs GLOBALES (ResÃºmenes)
    // ========================================
    {
      "title": "Peru's Central Bank Cuts Interest Rate to 5.75%",
      "content": "Peru's central bank reduced its benchmark interest rate by 25 basis points to 5.75% on Thursday, the first cut in 18 months...",  // â† TRUNCADO
      "source": "NewsAPI",
      "date": "2024-03-14T21:00:00",
      "url": "https://www.reuters.com/markets/americas/peru-central-bank-rate-cut/",
      "image_url": null,
      "method": "External API"
    },
    {
      "title": "BCR de PerÃº reduce tasa de referencia",
      "content": "El Banco Central de Reserva del PerÃº redujo su tasa de interÃ©s de referencia a 5.75%, segÃºn anunciÃ³ hoy...",  // â† SNIPPET
      "source": "TheNewsAPI",
      "date": "2024-03-14T19:30:00",
      "url": "https://www.bloomberg.com/...",
      "image_url": "https://assets.bwbx.io/...",
      "method": "External API"
    }
  ]
}
```

### ğŸ“‹ ComparaciÃ³n de Contenido

| Campo | Local (La RepÃºblica) | API Global (NewsAPI) |
|-------|---------------------|---------------------|
| **title** | Completo | Completo |
| **content** | **2,500+ caracteres** (artÃ­culo completo) | **~200 caracteres** (snippet) |
| **source** | "La RepÃºblica" | "NewsAPI" |
| **date** | Fecha exacta de publicaciÃ³n | Fecha de indexaciÃ³n (puede diferir) |
| **url** | Link directo al artÃ­culo | Link original (puede requerir paywall) |
| **image_url** | URL de imagen optimizada | Puede ser null |
| **method** | "CSS Selector" / "JSON-LD" / "Browser" | "External API" |

---

## ğŸ”§ OPTIMIZACIONES PROPUESTAS

### 1. Aumentar Timeout (SoluciÃ³n Inmediata)

```python
# EN: src/tools.py
response = requests.get(
    endpoint,
    params=params,
    timeout=90,  # â† CAMBIAR DE 30 A 90
    headers={"User-Agent": "MultiAgent-NewsSystem/1.0"},
)
```

**Pros:**
- âœ… Simple, un cambio de 1 lÃ­nea
- âœ… Obtienes las 5 fuentes (locales + APIs)
- âœ… Contenido completo para anÃ¡lisis profundo

**Contras:**
- âŒ El Investigator esperarÃ¡ ~60-90s por cada bÃºsqueda
- âŒ Si Infobae falla, todo el request se cuelga

---

### 2. BÃºsqueda Adaptativa (Avanzada)

```python
def _run(self, query: str, max_results: Optional[int] = None) -> str:
    """BÃºsqueda con fallback automÃ¡tico"""
    
    # Intentar primero con timeout largo (obtener todo)
    try:
        return self._search_with_timeout(query, max_results, timeout=90)
    except requests.Timeout:
        logger.warning("â±ï¸ Timeout en bÃºsqueda profunda, intentando rÃ¡pida...")
        # Fallback: Solo APIs rÃ¡pidas
        return self._search_with_timeout(query, max_results, timeout=10)
```

---

### 3. Endpoint Selectivo en ScraperRalf (Requiere modificar tu API)

Crear nuevos endpoints en tu ScraperRalf:

```python
# EN TU SCRAPERRALF: app.py

@app.route('/api/search/fast')
def search_fast():
    """Solo APIs globales: NewsAPI + TheNewsAPI"""
    # Tiempo: ~5 segundos
    # Usa solo: newsapi.py + thenewsapi.py
    pass

@app.route('/api/search/deep')
def search_deep():
    """Solo scrapers locales: El Comercio + La RepÃºblica + Infobae"""
    # Tiempo: ~60-90 segundos
    # Usa solo: elcomercio.py + larepublica.py + infobae.py
    pass

@app.route('/api/search/hybrid')
def search_hybrid():
    """Primero APIs (5s), luego scrapers en background"""
    # Retorna inmediatamente con APIs
    # Scrapers se agregan vÃ­a webhooks o polling
    pass
```

Luego en MultiAgent:

```python
# Fase 1: Contexto rÃ¡pido
fast_response = requests.get(
    "http://127.0.0.1:5000/api/search/fast",
    params={"q": query, "max_results": 3},
    timeout=10
)

# Fase 2: Contenido profundo (solo si el Analista lo requiere)
if analysis_requires_deep_content:
    deep_response = requests.get(
        "http://127.0.0.1:5000/api/search/deep",
        params={"q": query, "max_results": 2},
        timeout=90
    )
```

---

## ğŸ¯ RECOMENDACIÃ“N FINAL

### Para ProducciÃ³n Inmediata:

**OpciÃ³n Simple:** Aumentar timeout a 90s

```python
# src/tools.py - lÃ­nea 123
timeout=90  # Cambiar de 30 a 90
```

**JustificaciÃ³n:**
- El Investigator solo busca **1 vez** por iteraciÃ³n
- Esperar 90s para obtener contenido completo es aceptable
- El LLM necesita **citas textuales** que solo las fuentes locales proveen
- Las APIs globales darÃ¡n snippets truncados que no sirven para anÃ¡lisis

### Para Futuro (OptimizaciÃ³n Avanzada):

**OpciÃ³n Avanzada:** Implementar bÃºsqueda en dos fases

1. Modificar ScraperRalf para tener `/api/search/fast` y `/api/search/deep`
2. Llamar primero a `fast` (5s) para obtener contexto
3. El LLM decide si necesita profundizar
4. Si es necesario, llamar a `deep` (90s)

---

## ğŸ“Š COMPARACIÃ“N DE RENDIMIENTO

### Escenario: "Buscar 'crisis econÃ³mica PerÃº 2024'"

#### ConfiguraciÃ³n Actual (timeout=30s):
```
Tiempo total: 30s (timeout)
Resultados obtenidos:
âœ… NewsAPI: 3 artÃ­culos (snippets)
âœ… TheNewsAPI: 3 artÃ­culos (snippets)
âš ï¸ El Comercio: 2 artÃ­culos (parcial, cortado a 30s)
âŒ La RepÃºblica: 0 artÃ­culos (timeout)
âŒ Infobae: 0 artÃ­culos (timeout)

Total Ãºtil: 8 artÃ­culos con contenido limitado
```

#### ConfiguraciÃ³n Propuesta (timeout=90s):
```
Tiempo total: 75s (mÃ¡ximo de Infobae)
Resultados obtenidos:
âœ… NewsAPI: 3 artÃ­culos (snippets) - 3s
âœ… TheNewsAPI: 3 artÃ­culos (snippets) - 3s
âœ… El Comercio: 3 artÃ­culos (completos) - 35s
âœ… La RepÃºblica: 3 artÃ­culos (completos) - 50s
âœ… Infobae: 3 artÃ­culos (completos) - 75s

Total Ãºtil: 15 artÃ­culos con 9 de contenido COMPLETO
```

**Ganancia:**
- +87% mÃ¡s artÃ­culos
- +9 fuentes con texto completo (antes 0)
- Tiempo extra: +45 segundos (aceptable para calidad)

---

# ğŸ“‹ CHEATSHEET - Referencia RÃ¡pida

## Comandos Esenciales

### InstalaciÃ³n
```bash
# Windows
install.bat

# Linux/Mac
chmod +x install.sh
./install.sh

# Manual
pip install -r requirements.txt
```

### VerificaciÃ³n
```bash
python setup_check.py
```

### EjecuciÃ³n
```bash
# Con dashboard (recomendado)
python app.py

# Solo CLI
python test_simple.py "Tu tema aquÃ­"
```

## URLs y Puertos

| Servicio | URL | PropÃ³sito |
|----------|-----|-----------|
| Dashboard | http://localhost:8080 | Interfaz visual |
| API REST | http://localhost:8080/api/* | Endpoints |
| Socket.IO | ws://localhost:8080/agents | Eventos en vivo |
| ScraperRalf | http://localhost:5000 | BÃºsqueda de noticias |
| API_RALF | (configurar en .env) | LLM personalizado |

## Estructura de Archivos

```
ğŸ“ MultiAgent_AI_R/
â”œâ”€â”€ ğŸ“„ .env                 â† ConfiguraciÃ³n (EDITAR)
â”œâ”€â”€ ğŸš€ app.py               â† Servidor principal
â”œâ”€â”€ ğŸ§ª test_simple.py       â† Test rÃ¡pido CLI
â”œâ”€â”€ ğŸ” setup_check.py       â† Verificador
â”œâ”€â”€ ğŸ“¦ requirements.txt     â† Dependencias
â”œâ”€â”€ ğŸ“– README.md            â† DocumentaciÃ³n principal
â”œâ”€â”€ ğŸš¦ QUICKSTART.md        â† GuÃ­a rÃ¡pida
â”œâ”€â”€ ğŸ—ï¸ ARCHITECTURE.md      â† Arquitectura detallada
â”‚
â”œâ”€â”€ ğŸ“ src/
â”‚   â”œâ”€â”€ llm_config.py       â† Config LLM
â”‚   â”œâ”€â”€ tools.py            â† Herramientas
â”‚   â”œâ”€â”€ callbacks.py        â† Eventos
â”‚   â””â”€â”€ crew.py             â† Agentes y lÃ³gica
â”‚
â””â”€â”€ ğŸ“ templates/
    â””â”€â”€ index.html          â† Dashboard UI
```

## Variables de Entorno (.env)

```bash
# CRÃTICO: Configurar antes de usar
DOMINIO_API_RALF=tu-dominio.com
RALF_API_KEY=opcional
RALF_MODEL_NAME=ralf-mixed-model

# Opcionales
SCRAPER_BASE_URL=http://localhost:5000
FLASK_PORT=8080
MAX_ITERATIONS=5
```

## Agentes y Temperatures

| Agente | Role | Temperature | Herramientas |
|--------|------|-------------|--------------|
| Manager | Coordinador | 0.6 | - |
| Investigador | BÃºsqueda | 0.3 | NewsSearchTool |
| Analista | VerificaciÃ³n | 0.5 | - |
| Redactor | Escritura | 0.8 | - |

## API REST Endpoints

### POST /api/generate
```bash
curl -X POST http://localhost:8080/api/generate \
  -H "Content-Type: application/json" \
  -d '{"topic": "Inteligencia artificial en medicina"}'
```

### GET /api/result/{session_id}
```bash
curl http://localhost:8080/api/result/{session_id}
```

### GET /api/health
```bash
curl http://localhost:8080/api/health
```

## Eventos Socket.IO

### Conectar
```javascript
const socket = io('http://localhost:8080/agents');
```

### Unirse a sesiÃ³n
```javascript
socket.emit('join_session', {session_id: 'xxx'});
```

### Escuchar eventos
```javascript
socket.on('agent_start', (data) => {
  console.log('Agente:', data.agent);
  console.log('Tarea:', data.task);
});

socket.on('generation_complete', (data) => {
  console.log('ArtÃ­culo:', data.article);
});
```

## Troubleshooting RÃ¡pido

### "No se puede importar X"
```bash
pip install -r requirements.txt --upgrade
```

### "API_RALF no conecta"
1. Verificar DOMINIO_API_RALF en .env
2. Probar: `curl https://tu-dominio.com/v1`

### "ScraperRalf no disponible"
1. Verificar que corre en puerto 5000
2. Probar: `curl http://localhost:5000/api/search?q=test`

### "Socket.IO no conecta"
1. Abrir F12 en navegador â†’ Console
2. Verificar URL correcta
3. Deshabilitar firewall temporalmente

## PersonalizaciÃ³n

### Cambiar temperature de agente
```python
# En src/crew.py
def get_investigator_llm():
    return config.get_llm(temperature=0.3)  # â† Cambiar
```

### Agregar nueva herramienta
```python
# En src/tools.py
class MiHerramienta(BaseTool):
    name = "mi_tool"
    description = "..."
    
    def _run(self, input: str) -> str:
        # Tu lÃ³gica aquÃ­
        return resultado
```

### Modificar personalidad
```python
# En src/crew.py â†’ create_*_agent()
backstory=(
    "Tu nueva personalidad aquÃ­..."
)
```

## Logs y Debug

### Ver logs detallados
```bash
# Flask muestra logs automÃ¡ticamente
python app.py

# O en nivel DEBUG
export FLASK_DEBUG=True  # Linux/Mac
set FLASK_DEBUG=True     # Windows
python app.py
```

### Logs de agentes
Los agentes ya tienen `verbose=True`, mostrarÃ¡n pensamiento en consola.

## Testing

### Test completo
```bash
python test_simple.py "Avances en IA"
```

### Test por componente
```bash
# LLM
python src/llm_config.py

# Herramientas
python src/tools.py

# Callbacks
python src/callbacks.py

# Crew completa
python src/crew.py
```

## TeorÃ­a RÃ¡pida (AIMA)

### HTN (Cap. 11.3)
- Tarea compuesta: "Producir Noticia"
- DescomposiciÃ³n: Buscar â†’ Validar â†’ Redactar

### Vigilancia (Cap. 12.5)
- Analista verifica precondiciones
- Si falla â†’ replanificaciÃ³n (loop)

### Multiagente (Cap. 17)
- CoordinaciÃ³n jerÃ¡rquica (Manager-Worker)
- ComunicaciÃ³n por artefactos (no negociaciÃ³n)

## Performance

### Tiempo promedio por artÃ­culo
- 1-3 minutos (depende de LLM y red)

### Optimizaciones posibles
1. CachÃ© de bÃºsquedas repetidas
2. Paralelizar bÃºsquedas (mÃºltiples queries)
3. Ajustar max_iterations (menor = mÃ¡s rÃ¡pido)

## Seguridad

### ProducciÃ³n
```bash
# Cambiar en .env
FLASK_SECRET_KEY=clave-super-segura-aleatoria
FLASK_DEBUG=False

# Configurar CORS especÃ­fico en app.py
CORS(app, origins=['https://tu-dominio.com'])
```

---

# ğŸ”§ RESOLUCIÃ“N DE PROBLEMAS CONOCIDOS

## Problema 1: Timeout del Investigador â±ï¸

### SÃ­ntoma
El Investigador no esperaba los 60-70s necesarios para que ScraperRalf completara la bÃºsqueda, resultando en datos incompletos.

### Causa RaÃ­z
El LLM tenÃ­a un timeout de 60s, pero ScraperRalf necesita ~67s para completar todas las fuentes (especialmente las locales).

### SoluciÃ³n Implementada âœ…

**Archivo modificado:** [src/llm_config.py](src/llm_config.py#L85)

```python
# ANTES
ChatOpenAI(..., timeout=60)

# DESPUÃ‰S  
ChatOpenAI(..., timeout=120, max_retries=3)  # Suficiente para ScraperRalf (~67s)
```

**JustificaciÃ³n:**
- ScraperRalf tarda ~67s en el mejor caso
- Timeout de 120s da margen de 53s adicionales
- Cubre casos donde Infobae tarda hasta 90s

### VerificaciÃ³n

Ejecutar el sistema y verificar en los logs:

```
ğŸ”´ğŸ”´ğŸ”´ INVESTIGADOR LLAMÃ“ A LA HERRAMIENTA NewsSearchTool ğŸ”´ğŸ”´ğŸ”´
â³ ESPERANDO RESPUESTA DE SCRAPERRALF... (esto puede tardar 60-70 segundos)

[... espera de 60-70 segundos ...]

ğŸŸ¢ğŸŸ¢ğŸŸ¢ HERRAMIENTA COMPLETADA - DATOS RECIBIDOS DE SCRAPERRALF ğŸŸ¢ğŸŸ¢ğŸŸ¢
â±ï¸ Tiempo de espera: 67.42 segundos
ğŸ“Š TIER 1 (Fuentes Locales): 13 artÃ­culos
```

---

## Problema 2: "Esquizofrenia Temporal" ğŸ•°ï¸

### SÃ­ntoma
El sistema fallaba con error **"MÃ¡ximo de iteraciones alcanzado sin aprobaciÃ³n"** porque el Analista rechazaba noticias de 2026 como "FALACIAS DE FUTURO CONSUMADO".

### Causa RaÃ­z
- ScraperRalf devolvÃ­a noticias fechadas "4 de enero de 2026" (fecha real)
- El Analista creÃ­a que estaba en "Mayo de 2024"
- Rechazaba todas las noticias como temporalmente imposibles

### SoluciÃ³n Implementada âœ…

**PropagaciÃ³n de fecha dinÃ¡mica en todo el sistema:**

```python
# app.py
from datetime import datetime
current_date = datetime.now().strftime("%Y-%m-%d")  # 2026-01-04

# Pasada a todos los agentes
def create_bias_analyst_agent(current_date):
    return Agent(
        goal=f"âš ï¸ CONTEXTO TEMPORAL: HOY ES {current_date}. Validar credibilidad...",
        backstory=f"ğŸ“… FECHA ACTUAL: {current_date} - Esta es tu realidad temporal..."
    )
```

**Flujo de fecha:**
```
app.py â†’ generate_news_article(topic, session_id, current_date)
       â†’ NewsCrew.run(topic, current_date)
       â†’ create_bias_analyst_agent(current_date)
       â†’ create_investigation_task(agent, topic, current_date)
```

### VerificaciÃ³n

Los logs deben mostrar:

```
ğŸ“… CONTEXTO TEMPORAL: Hoy es 2026-01-04
ğŸ” ANALISTA - FECHA DE CONTEXTO: 2026-01-04
âœ… Analista veredicto: APROBADO  â† No rechaza por fechas
```

---

## Problema 3: ArtÃ­culos Desordenados en Frontend ğŸ“°

### SÃ­ntoma
Los artÃ­culos se mostraban como texto plano sin la estructura visual de una revista profesional.

### Soluciones Implementadas âœ…

#### A) Parser Markdown Mejorado (15+ mejoras)

**Archivo:** [templates/index.html](templates/index.html) - FunciÃ³n `displayResult()`

**Mejoras clave:**

1. **Headers jerÃ¡rquicos** con tipografÃ­a profesional:
   - H1: `text-4xl md:text-6xl font-black text-[#9D1A10]`
   - H2: `text-2xl md:text-3xl border-b-2 border-[#9D1A10]`
   - H3: `text-xl md:text-2xl border-l-4 border-[#9D1A10]`

2. **Lead destacado** (primer pÃ¡rrafo en negrita):
   ```html
   text-xl md:text-2xl font-semibold border-l-4 border-[#9D1A10] bg-neutral-50
   ```

3. **Blockquotes estilo revista**:
   ```html
   border-l-4 border-[#9D1A10] bg-neutral-50 pl-6 italic text-lg shadow-sm
   ```

4. **Links con indicador externo**:
   - Color corporativo `#9D1A10`
   - Ãcono "â†—" para links externos
   - Hover con `decoration-wavy`

5. **CÃ³digo inline y bloques**:
   - Inline: `bg-red-50 text-[#9D1A10] border border-red-100`
   - Bloques: `bg-neutral-900 text-green-400 rounded-xl shadow-lg`

6. **PÃ¡rrafos justificados** tipo revista:
   ```html
   text-lg leading-relaxed text-neutral-700 text-justify mb-6
   ```

#### B) Instrucciones Detalladas para Redactor

**Archivo:** [src/crew.py](src/crew.py) - FunciÃ³n `create_writing_task()`

**Plantilla estructurada completa:**

```markdown
# TÃTULO (mÃ¡x 12 palabras)

**[LEAD EN NEGRITA: 2-3 oraciones]**

## Contexto e IntroducciÃ³n
...

> "Cita textual"
> â€” Autor, Cargo

## Desarrollo Principal

### Primer Aspecto
- **Dato 1**: ExplicaciÃ³n
- **Dato 2**: Contexto

---

## AnÃ¡lisis de Sesgos
...

## ConclusiÃ³n
...
```

**Checklist de calidad obligatorio:**
```
âœ… UN SOLO H1
âœ… Lead en negrita al inicio
âœ… MÃ­nimo 4 secciones H2
âœ… Subsecciones H3
âœ… 2-3 blockquotes
âœ… Listas con viÃ±etas
âœ… 900-1400 palabras
âœ… Tono periodÃ­stico profesional
```

**Referencias de estilo:**
- The New York Times
- El PaÃ­s
- The Guardian
- Le Monde

### VerificaciÃ³n

El artÃ­culo final debe verse como una publicaciÃ³n profesional con:
- TipografÃ­a clara y jerÃ¡rquica
- Espaciado apropiado entre secciones
- Citas destacadas visualmente
- Lead impactante al inicio
- Estructura lÃ³gica y fluida

---

## DiagnÃ³stico de Timeout de ScraperRalf ğŸ”

### VerificaciÃ³n de Tiempos

Para confirmar que ScraperRalf estÃ¡ devolviendo datos completos:

**Script de test:**
```bash
python test_scraper_timing.py
```

**Resultado esperado:**
```
âœ… ScraperRalf responde en ~67.89 segundos
âœ… Fuentes Tier 1 (locales): 13 artÃ­culos
âœ… Contenido promedio: 3,862 caracteres
```

### Logging Mejorado

**Archivo:** [src/tools.py](src/tools.py)

**Salida detallada:**
```
ğŸ” INICIO BÃšSQUEDA: 'tema' (max: 5 por fuente)
â±ï¸ Timestamp: 17:41:25

[... espera ...]

âœ… RESPUESTA RECIBIDA en 67.89 segundos
â±ï¸ Inicio: 17:41:25 â†’ Fin: 17:42:33

ğŸ“Š ANÃLISIS DE DISTRIBUCIÃ“N POR TIER:
   ğŸŸ¢ TIER 1 (Fuentes Locales): 13 artÃ­culos
   ğŸŸ¡ TIER 2 (APIs Globales): 0 artÃ­culos
   ğŸ“ Longitud promedio Tier 1: 3862 caracteres
```

### Alerta de Timeout

Si solo se reciben APIs globales:

```
âš ï¸ ADVERTENCIA: Solo APIs globales recibidas. Scrapers locales no respondieron.
   Posibles causas:
   1. ScraperRalf tiene timeout interno < 90s
   2. Scrapers locales estÃ¡n fallando
   3. Camoufox no instalado: 'camoufox fetch'
```

---

## Resumen de Mejoras Implementadas ğŸ¯

| Problema | SoluciÃ³n | Archivo Modificado | Estado |
|----------|----------|-------------------|--------|
| Timeout LLM (60s vs 67s) | Aumentar a 120s | [src/llm_config.py](src/llm_config.py#L85) | âœ… |
| Esquizofrenia temporal | Fecha dinÃ¡mica en agentes | [src/crew.py](src/crew.py), [app.py](app.py) | âœ… |
| ArtÃ­culos desordenados | Parser MD + instrucciones | [templates/index.html](templates/index.html), [src/crew.py](src/crew.py) | âœ… |
| Logging insuficiente | Timestamps + distribuciÃ³n | [src/tools.py](src/tools.py), [src/callbacks.py](src/callbacks.py) | âœ… |
| max_iter bajo | Aumentar de 3 a 5 | [src/crew.py](src/crew.py#L105) | âœ… |
| **Ceguera Temporal** | Grounding temporal con filtrado | [src/crew.py](src/crew.py) | âœ… |
| **Sesgo Regional** | Protocolo bÃºsqueda estructurada (SOP) | [src/crew.py](src/crew.py) | âœ… |
| **Falta validaciÃ³n lÃ³gica** | Sanity Check matemÃ¡tico/temporal | [src/crew.py](src/crew.py) | âœ… |

**Tiempo promedio por artÃ­culo:** 1-3 minutos (incluye espera de ScraperRalf)

**Calidad esperada:** ArtÃ­culos con estructura profesional, datos verificados y formato de revista digital.

---

# ğŸ“š DocumentaciÃ³n Completa

## VerificaciÃ³n de Timeout y ScraperRalf

### âœ… VerificaciÃ³n TÃ©cnica del Timeout

El sistema estÃ¡ **correctamente configurado** para esperar la respuesta completa de ScraperRalf.

#### ConfiguraciÃ³n en `src/tools.py` (LÃ­neas 127-145)

```python
# Timeout de 90s para permitir que scrapers locales completen
# ScraperRalf ejecuta las 5 fuentes en paralelo:
# - APIs globales (NewsAPI, TheNewsAPI): ~3-5s
# - El Comercio (JSON-LD): ~30-45s
# - La RepÃºblica (CSS): ~45-60s
# - Infobae (Camoufox): ~60-90s
response = requests.get(
    endpoint,
    params=params,
    timeout=90,  # Python BLOQUEA aquÃ­ hasta recibir respuesta completa
    headers={"User-Agent": "MultiAgent-NewsSystem/1.0"},
)
```

#### Â¿QuÃ© significa `timeout=90`?

**Comportamiento de `requests.get(timeout=90)`:**

1. **Python BLOQUEA la ejecuciÃ³n** del cÃ³digo en esta lÃ­nea
2. **Espera hasta 90 segundos** a que ScraperRalf devuelva la respuesta completa
3. **NO continÃºa** hasta que:
   - ScraperRalf devuelva el JSON completo con todas las fuentes, **O**
   - Pasen 90 segundos (entonces lanza `requests.Timeout`)

**Â¿El agente Investigador espera?**  
âœ… **SÃ**. El cÃ³digo Python estÃ¡ bloqueado en `response = requests.get(...)` hasta que ScraperRalf complete.

#### Flujo de EjecuciÃ³n Paso a Paso

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ T=0s: Investigador llama NewsSearchTool._run()                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ T=0s: Python ejecuta:                                           â”‚
â”‚   response = requests.get(                                      â”‚
â”‚       "http://127.0.0.1:5000/api/search",                      â”‚
â”‚       params={"q": "tema", "max_results": 5},                  â”‚
â”‚       timeout=90                                                â”‚
â”‚   )                                                             â”‚
â”‚                                                                 â”‚
â”‚ âš ï¸ EL CÃ“DIGO SE DETIENE AQUÃ Y ESPERA âš ï¸                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ T=0-3s: ScraperRalf lanza 5 threads en paralelo:               â”‚
â”‚   â€¢ Thread 1: NewsAPI       â†’ Responde en ~3s                  â”‚
â”‚   â€¢ Thread 2: TheNewsAPI    â†’ Responde en ~3s                  â”‚
â”‚   â€¢ Thread 3: El Comercio   â†’ Responde en ~35s                 â”‚
â”‚   â€¢ Thread 4: La RepÃºblica  â†’ Responde en ~50s                 â”‚
â”‚   â€¢ Thread 5: Infobae       â†’ Responde en ~75s (Camoufox)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â”‚ â³ Python/Investigador ESPERANDO...
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ T=75s: ScraperRalf consolida resultados de los 5 threads      â”‚
â”‚   â€¢ NewsAPI: 3 artÃ­culos (snippets)                            â”‚
â”‚   â€¢ TheNewsAPI: 3 artÃ­culos (snippets)                         â”‚
â”‚   â€¢ El Comercio: 3 artÃ­culos completos (JSON-LD)               â”‚
â”‚   â€¢ La RepÃºblica: 3 artÃ­culos completos (CSS)                  â”‚
â”‚   â€¢ Infobae: 3 artÃ­culos completos (Camoufox)                  â”‚
â”‚                                                                 â”‚
â”‚ Total: 15 artÃ­culos                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ T=75s: ScraperRalf devuelve JSON completo                      â”‚
â”‚   {                                                             â”‚
â”‚     "results": [                                                â”‚
â”‚       { "source": "La RepÃºblica", "content": "..." },          â”‚
â”‚       { "source": "El Comercio", "content": "..." },           â”‚
â”‚       { "source": "Infobae", "content": "..." },               â”‚
â”‚       ...                                                       â”‚
â”‚     ]                                                           â”‚
â”‚   }                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ T=75s: Python CONTINÃšA la ejecuciÃ³n                            â”‚
â”‚   response.raise_for_status()  # OK                            â”‚
â”‚   data = response.json()       # Parsea JSON completo          â”‚
â”‚                                                                 â”‚
â”‚ âœ… Investigador ahora tiene 15 artÃ­culos completos             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### ClasificaciÃ³n por Tiers

**LÃ­neas 152-169 en `src/tools.py`:**

```python
# Tier 1: Fuentes locales con contenido completo
is_deep_source = source in ["La RepÃºblica", "El Comercio", "Infobae"]

# Tier 2: APIs globales con snippets
is_api_source = source in ["NewsAPI", "TheNewsAPI"]

formatted_results.append({
    "id": idx,
    "title": item.get("title", "Sin tÃ­tulo"),
    "content": content,
    "source": source,
    "url": item.get("url", ""),
    "date": item.get("date", ""),
    "tier": "deep" if is_deep_source else ("api" if is_api_source else "unknown"),
    "content_length": len(content),
    "extraction_method": item.get("method", "unknown"),
})
```

**Resumen en JSON de respuesta (LÃ­neas 188-194):**

```python
return json.dumps({
    "status": "success",
    "query": query,
    "total_results": len(formatted_results),
    "deep_sources_count": sum(1 for r in formatted_results if r["tier"] == "deep"),
    "api_sources_count": sum(1 for r in formatted_results if r["tier"] == "api"),
    "results": formatted_results,
})
```

---

## ğŸš€ Mejoras CrÃ­ticas Implementadas (Enero 2026)

### 1. Grounding Temporal - SoluciÃ³n a "Ceguera Temporal"

**Problema Original:**
El agente recuperaba artÃ­culos antiguos (2021-2022) que especulaban sobre eventos futuros ya ocurridos.

**SoluciÃ³n Implementada:**

```python
# En create_investigator_agent(current_date: str = "")
if not current_date:
    from datetime import datetime
    current_date = datetime.now().strftime("%Y-%m-%d")

# Calcular umbral de antigÃ¼edad (hace 24 meses)
threshold_date = (datetime.strptime(current_date, "%Y-%m-%d") - timedelta(days=730)).strftime("%Y-%m-%d")

goal=(
    f"ğŸ“… CONTEXTO TEMPORAL CRÃTICO:\n"
    f"HOY ES: {current_date}\n"
    f"UMBRAL DE ANTIGÃœEDAD: {threshold_date} (hace 24 meses)\n\n"
    f"âŒ FILTRO TEMPORAL ABSOLUTO:\n"
    f"- RECHAZAR automÃ¡ticamente cualquier artÃ­culo con fecha ANTERIOR a {threshold_date}\n"
    f"- Si una fuente especula sobre eventos YA OCURRIDOS, DESCARTARLA\n"
)
```

**Resultado:**
- âœ… El agente descarta artÃ­culos de hace mÃ¡s de 24 meses
- âœ… Prioriza informaciÃ³n de los Ãºltimos 6 meses
- âœ… Ignora fuentes que hablan especulativamente de eventos ya ocurridos

### 2. Protocolo de BÃºsqueda Estructurada (SOP) - SoluciÃ³n a "Sesgo Regional"

**Problema Original:**
El agente solo buscaba fuentes peruanas/argentinas para temas globales (ej. Mundial FIFA).

**SoluciÃ³n Implementada:**

```python
"ğŸ“‹ PROTOCOLO DE BÃšSQUEDA ESTRUCTURADA (SOP) - 4 PASOS OBLIGATORIOS:\n\n"
"PASO 1: BÃšSQUEDA DE FUENTES OFICIALES\n"
"   â¤ Query especÃ­fica: '[tema] official statement'\n"
"   â¤ Buscar: FIFA.com, UN.org, Gov.pe, sitios gubernamentales\n\n"
"PASO 2: BÃšSQUEDA EN AGENCIAS INTERNACIONALES\n"
"   â¤ Query: '[tema] Reuters' o '[tema] AP'\n"
"   â¤ CRÃTICO: Si el tema es global y solo encuentras fuentes peruanas, BUSCAR MÃS\n\n"
"PASO 3: BÃšSQUEDA EN MEDIOS LOCALES\n"
"   â¤ Query: '[tema]' (general)\n"
"   â¤ Fuentes: La RepÃºblica, El Comercio\n\n"
"PASO 4: SANITY CHECK MATEMÃTICO Y LÃ“GICO\n"
```

**TriangulaciÃ³n Obligatoria:**
```python
"ğŸ¯ OBJETIVO PRINCIPAL:\n"
"Implementar TRIANGULACIÃ“N DE FUENTES obligatoria:\n"
"1. Al menos 1 fuente OFICIAL (FIFA, gobiernos, instituciones)\n"
"2. Al menos 1 agencia INTERNACIONAL (Reuters, AP, AFP, EFE)\n"
"3. Al menos 1 medio LOCAL (La RepÃºblica, El Comercio, etc.)\n"
```

**Resultado:**
- âœ… El agente ejecuta 3 bÃºsquedas separadas
- âœ… Evita el sesgo de un solo paÃ­s/regiÃ³n
- âœ… Garantiza balance de perspectivas

### 3. Sanity Check MatemÃ¡tico - SoluciÃ³n a "Falta de ValidaciÃ³n LÃ³gica"

**Problema Original:**
El agente pasaba datos matemÃ¡ticamente inconsistentes (ej. "12 grupos â†’ 24 clasifican, pero octavos de 16").

**SoluciÃ³n Implementada:**

```python
"ğŸ” SANITY CHECK FINAL (OBLIGATORIO):\n"
"Antes de finalizar, LEE TODO tu informe y verifica:\n\n"
"1. COHERENCIA NUMÃ‰RICA:\n"
"   - Si mencionas estadÃ­sticas relacionadas, verifica que sean coherentes\n"
"   - Formato de torneos: Â¿los nÃºmeros tienen sentido? (octavos = 16, cuartos = 8)\n\n"
"2. COHERENCIA TEMPORAL:\n"
"   - Â¿Todas las fuentes son posteriores al umbral de antigÃ¼edad?\n"
"   - Â¿Hay artÃ­culos especulando sobre eventos ya pasados?\n\n"
"3. COHERENCIA GEOGRÃFICA:\n"
"   - Si es tema global, Â¿tienes fuentes de al menos 2 regiones/paÃ­ses?\n\n"
"4. CONTRADICCIONES LÃ“GICAS:\n"
"   - Â¿Alguna fuente contradice a otra en datos clave?\n"
"   - Si sÃ­: Buscar una tercera fuente autoritativa para desempatar\n"
```

**Ejemplo Educativo Incluido:**
```python
"Tema: Mundial de FÃºtbol 2026\n"
"Dato encontrado: '12 grupos de 4 equipos'\n"
"Sanity Check: 12 Ã— 4 = 48 equipos total\n"
"Dato encontrado: 'Pasan los 2 primeros de cada grupo'\n"
"Sanity Check: 12 Ã— 2 = 24 equipos a octavos\n"
"Dato encontrado: 'Octavos de final con 16 equipos'\n"
"âš ï¸ CONTRADICCIÃ“N DETECTADA: 24 â‰  16\n"
"AcciÃ³n: Buscar '[tema] formato octavos de final' para aclarar\n"
```

**Resultado:**
- âœ… El agente valida la coherencia numÃ©rica antes de finalizar
- âœ… Detecta contradicciones lÃ³gicas entre fuentes
- âœ… Busca informaciÃ³n adicional cuando encuentra inconsistencias

### 4. Mejoras en el Analista de Sesgos

```python
"5. VALIDACIÃ“N DE COHERENCIA MATEMÃTICA Y LÃ“GICA (NUEVO):\n"
"   - Si hay estadÃ­sticas relacionadas, Â¿son coherentes?\n"
"   - Si se mencionan fases de torneo, Â¿los nÃºmeros cuadran?\n\n"
"6. TRIANGULACIÃ“N DE FUENTES (NUEVO):\n"
"   - Â¿Hay al menos 1 fuente oficial/autoritativa?\n"
"   - Â¿Hay al menos 1 fuente internacional para temas globales?\n"
"   - Si el tema es global y solo hay fuentes locales â†’ RECHAZAR por sesgo geogrÃ¡fico\n\n"
"7. VERIFICACIÃ“N TEMPORAL:\n"
"   - Â¿Las fuentes son recientes (Ãºltimos 24 meses preferentemente)?\n"
```

**Ejemplos de Rechazo Obligatorio:**
```python
"âŒ 'Solo fuentes peruanas/argentinas sobre tema global (Mundial FIFA)'\n"
"   â†’ Requiere: Buscar fuentes de FIFA.com, Reuters, AP\n"
"âŒ 'ContradicciÃ³n: 12 grupos â†’ 24 clasifican, pero dice octavos de 16'\n"
"   â†’ Requiere: Buscar 'formato oficial Mundial 2026 FIFA'\n"
```

---

## ğŸ§ª Testing y VerificaciÃ³n

### Test de Timing del Scraper

```bash
python test_scraper_timing.py
```

**QuÃ© verifica:**
1. âœ… Conectividad con ScraperRalf
2. â±ï¸ Tiempo de espera (esperado: 45-90s)
3. ğŸ“Š DistribuciÃ³n de fuentes (Tier 1 vs Tier 2)
4. ğŸ“ Longitud de contenido (>1000 chars para Tier 1)

**Resultados esperados:**
```
ğŸ‰ CONCLUSIÃ“N: El sistema estÃ¡ funcionando CORRECTAMENTE
   â€¢ El timeout de 90s es respetado
   â€¢ Las fuentes locales estÃ¡n entregando contenido completo
   â€¢ El Investigator recibirÃ¡ informaciÃ³n de calidad
```

### Logging en Tiempo Real

Cuando el Investigador ejecuta una bÃºsqueda:

```
ğŸ” Buscando: 'tema' (max: 5 resultados)
[... espera ~75 segundos ...]
âœ… Encontrados 15 artÃ­culos
ğŸ“Š DistribuciÃ³n: 9 fuentes locales (deep), 6 APIs globales
```

**InterpretaciÃ³n:**
- **9 fuentes locales:** 3 artÃ­culos Ã— 3 fuentes (La RepÃºblica, El Comercio, Infobae)
- **6 APIs globales:** 3 artÃ­culos Ã— 2 APIs (NewsAPI, TheNewsAPI)

âš ï¸ Si ves `0 fuentes locales (deep)` â†’ Indica timeout o fallo en scrapers locales

---

# ğŸ§ª Fundamentos TeÃ³ricos (Russell & Norvig - AIMA)

- **PlanificaciÃ³n HTN** (Cap. 11.3)
- **Vigilancia de EjecuciÃ³n** (Cap. 12.5)
- **Arquitecturas Multiagente** (Cap. 17)

Desarrollado con â¤ï¸ usando CrewAI y PlanificaciÃ³n HTN
